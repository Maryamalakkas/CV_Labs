{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2746 files belonging to 5 classes.\n",
      "Using 2197 files for training.\n",
      "Found 2746 files belonging to 5 classes.\n",
      "Using 549 files for validation.\n",
      "Found 924 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "#Data preprocessing\n",
    "# Load and preprocess the dataset\n",
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    '/Users/shahadaleissa/CV-labs/Data/archive/train',\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32\n",
    ")\n",
    "validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    '/Users/shahadaleissa/CV-labs/Data/archive/train',\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    '/Users/shahadaleissa/CV-labs/Data/archive/images',\n",
    "    seed=123,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data analysis \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_url = \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/5\"\n",
    "model = tf.keras.Sequential([\n",
    "    hub.KerasLayer(module_url, trainable=False),\n",
    "    layers.Dense(5, activation='softmax')  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure the dataset for performance\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_dataset = train_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 24s 305ms/step - loss: 1.4512 - accuracy: 0.4133 - val_loss: 1.3037 - val_accuracy: 0.4499\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 11s 162ms/step - loss: 1.2104 - accuracy: 0.5448 - val_loss: 1.2001 - val_accuracy: 0.5100\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 11s 160ms/step - loss: 1.1115 - accuracy: 0.5835 - val_loss: 1.1494 - val_accuracy: 0.5228\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 11s 159ms/step - loss: 1.0462 - accuracy: 0.6099 - val_loss: 1.1176 - val_accuracy: 0.5501\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 11s 158ms/step - loss: 0.9964 - accuracy: 0.6309 - val_loss: 1.0957 - val_accuracy: 0.5628\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 11s 158ms/step - loss: 0.9559 - accuracy: 0.6509 - val_loss: 1.0800 - val_accuracy: 0.5774\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 11s 159ms/step - loss: 0.9216 - accuracy: 0.6650 - val_loss: 1.0685 - val_accuracy: 0.5683\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 12s 174ms/step - loss: 0.8917 - accuracy: 0.6850 - val_loss: 1.0599 - val_accuracy: 0.5719\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 11s 163ms/step - loss: 0.8652 - accuracy: 0.6964 - val_loss: 1.0536 - val_accuracy: 0.5792\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 11s 165ms/step - loss: 0.8413 - accuracy: 0.7051 - val_loss: 1.0490 - val_accuracy: 0.5829\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 15 # Adjust the number of epochs as needed\n",
    "history = model.fit(train_dataset, epochs=epochs, validation_data=validation_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 2s 48ms/step - loss: 8.7687 - accuracy: 0.2673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8.768701553344727, 0.2673160135746002]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
